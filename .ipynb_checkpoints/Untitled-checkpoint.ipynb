{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b03770e-6a5f-46fd-9ca6-15ff6db7cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7e9a3-d266-430b-8159-9a7f70178732",
   "metadata": {},
   "source": [
    "We solve the following 1d homogenenous wave equation:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "&u_{tt} - c^2u_{xx} = 0, 0 < x < L, t > 0 \\\\\n",
    "&u(0, t) = u(L, t) = 0\\\\\n",
    "&u(x, 0) = \\cos\\frac{\\pi x}{2L}, u_t(x, 0) = 0\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "The theoretical solution of it is:\n",
    "$$ u(x, t) = \\cos\\frac{\\pi ct}{2L}\\cos\\frac{\\pi x}{2L}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f88d6c-c935-4bc8-b9db-278191b54d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2\n",
    "L = 1\n",
    "T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fe6a87-3c2f-42cc-8382-41cf5d52b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    \"\"\"Fully connected neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.linears.append(nn.Linear(layer_sizes[i-1], layer_sizes[i]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for linear in self.linears[:-1]:\n",
    "            x = torch.tanh(linear(x))\n",
    "            # x = torch.sin(linear(x))\n",
    "        x = self.linears[-1](x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63270bf0-a00e-4fd8-b6de-caae55932a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    \"\"\"Physic informed neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, c, L, T, layer_sizes, Ni, Nb, Nc):\n",
    "        super(PINN, self).__init__()\n",
    "        self.L = L\n",
    "        self.c = c \n",
    "        self.T = T\n",
    "        \n",
    "        # Initial condition\n",
    "        xi = np.random.uniform(0, L, (Ni, 1))\n",
    "        self.xi = torch.tensor(xi, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.t0 = torch.zeros(Ni, 1, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        \n",
    "        # Boundary condition\n",
    "        ta = np.random.uniform(0, T, (Nb, 1))\n",
    "        xa = np.ones((Nb, 1)) * 0\n",
    "        self.ta = torch.tensor(ta, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.xa = torch.tensor(xa, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        tb = np.random.uniform(0, T, (Nb, 1))\n",
    "        xb = np.ones((Nb, 1)) * L\n",
    "        self.tb = torch.tensor(tb, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.xb = torch.tensor(xb, dtype=torch.float32, requires_grad=True, device=device)        \n",
    "        \n",
    "        # Collocation points\n",
    "        xf = np.random.uniform(0, L, (Nc, 1))\n",
    "        tf = np.random.uniform(0, T, (Nc, 1))\n",
    "        self.xf = torch.tensor(xf, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.tf = torch.tensor(tf, dtype=torch.float32, requires_grad=True, device=device)\n",
    "                     \n",
    "        self.dnn = DNN(layer_sizes).to(device)\n",
    "        self.num_iter = 0\n",
    "        self.max_num_iter = 50000\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.dnn.parameters(),\n",
    "            lr = 0.0001,\n",
    "        )\n",
    "        \n",
    "    def net_u(self, x, t):\n",
    "        u = self.dnn(torch.cat((x, t), dim=1))\n",
    "        return u \n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_tt = torch.autograd.grad(\n",
    "            u_t, t, \n",
    "            grad_outputs=torch.ones_like(u_t),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        Lu = u_tt  - self.c**2 * u_xx\n",
    "        return Lu \n",
    "    \n",
    "    def initial_loss(self):\n",
    "        u = self.net_u(self.xi, self.t0)\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, self.t0, \n",
    "            grad_outputs=torch.ones_like(u), \n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        li = torch.mean(torch.square(u - torch.cos(np.pi * self.xi / (2 * L)))) + torch.mean(torch.square(u_t))\n",
    "        self.loss_i.append(li.item())\n",
    "        return li\n",
    "    \n",
    "    def boundary_loss(self):\n",
    "        ua = self.net_u(self.xa, self.ta)\n",
    "        ub = self.net_u(self.xb, self.tb)\n",
    "        lb = torch.mean(torch.square(ua)) +\\\n",
    "             torch.mean(torch.square(ub))\n",
    "        self.loss_b.append(lb.item())\n",
    "        return lb\n",
    "                        \n",
    "    def collocation_loss(self):\n",
    "        Lu = self.net_f(self.xf, self.tf)\n",
    "        lc = torch.mean(torch.square(Lu))\n",
    "        self.loss_c.append(lc.item())\n",
    "        return lc\n",
    "    \n",
    "    def compute_loss(self, l1, l2, l3, print_interval):\n",
    "        li = self.initial_loss()\n",
    "        lb = self.boundary_loss()\n",
    "        lc = self.collocation_loss()\n",
    "        l = l1 * li + l2 * lb + l3 * lc \n",
    "        # self.loss.append(l.item())\n",
    "        if self.num_iter % print_interval == 0 or self.num_iter == self.max_num_iter:\n",
    "            self.loss.append(l.item())\n",
    "            print(\"Iter %d, Loss: %.4e, Initial loss: %.4e, Boundary loss: %.4e, Collocation loss : %.4e\" \n",
    "                  % (self.num_iter, l.item(), li.item(), lb.item(), lc.item()))\n",
    "        return l\n",
    "\n",
    "    def train(self, l1=1, l2=1, l3=1, print_interval=100):\n",
    "        self.loss_i = []\n",
    "        self.loss_b = []\n",
    "        self.loss_c = []\n",
    "        self.loss = []\n",
    "        self.dnn.train()\n",
    "        while self.num_iter < self.max_num_iter:\n",
    "            l = self.compute_loss(l1, l2, l3, print_interval)\n",
    "            self.optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            self.optimizer.step()\n",
    "            self.num_iter += 1\n",
    "            \n",
    "    def predict(self, x, t):\n",
    "        self.dnn.eval() \n",
    "        x = torch.tensor(x, requires_grad=True, dtype=torch.float32, device=device)\n",
    "        t = torch.tensor(t, requires_grad=True, dtype=torch.float32, device=device)\n",
    "        u = self.net_u(x, t)\n",
    "        Lu = self.net_f(x, t)\n",
    "        u = u.detach().cpu().numpy()\n",
    "        Lu = Lu.detach().cpu().numpy()\n",
    "        return u, Lu\n",
    "    \n",
    "    # def plot_loss(self):\n",
    "    #     fig = plt.figure()\n",
    "    #     ax1 = fig.add_subplot(151)\n",
    "    #     ax1.plot(self.loss)\n",
    "    #     ax1.set_title('Loss')\n",
    "    #     ax2 = fig.add_subplot(152)\n",
    "    #     ax2.plot(self.loss_i)\n",
    "    #     ax2.set_title('Initial Loss')\n",
    "    #     ax3 = fig.add_subplot(153)\n",
    "    #     ax3.plot(self.loss_b)\n",
    "    #     ax3.set_title('Boundary Loss')\n",
    "    #     ax4 = fig.add_subplot(154)\n",
    "    #     ax4.plot(self.loss_c1)\n",
    "    #     ax4.set_title('Collocation Loss 1')\n",
    "    #     ax5 = fig.add_subplot(155)\n",
    "    #     ax5.plot(self.loss_c2)\n",
    "    #     ax5.set_title('Collocation Loss 2')\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb615e2-74b6-495b-851b-bb8f0018c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [2] + [64] * 8 + [1]\n",
    "Ni = 1000\n",
    "Nb = 1000\n",
    "Nc = 10000\n",
    "model = PINN(c, L, T, layer_sizes, Ni, Nb, Nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823635b9-7f81-4ce1-85df-ed5da7a2383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss: 5.3070e-01, Initial loss: 5.3064e-01, Boundary loss: 2.8191e-05, Collocation loss : 3.0759e-05\n",
      "Iter 500, Loss: 1.5202e-01, Initial loss: 5.8798e-02, Boundary loss: 8.7606e-02, Collocation loss : 5.6134e-03\n",
      "Iter 1000, Loss: 8.9778e-02, Initial loss: 2.7306e-02, Boundary loss: 5.8800e-02, Collocation loss : 3.6714e-03\n",
      "Iter 1500, Loss: 7.3620e-02, Initial loss: 2.2663e-02, Boundary loss: 4.9145e-02, Collocation loss : 1.8117e-03\n",
      "Iter 2000, Loss: 6.7924e-02, Initial loss: 1.8672e-02, Boundary loss: 4.7968e-02, Collocation loss : 1.2843e-03\n",
      "Iter 2500, Loss: 6.5796e-02, Initial loss: 1.7771e-02, Boundary loss: 4.6817e-02, Collocation loss : 1.2093e-03\n",
      "Iter 3000, Loss: 6.3951e-02, Initial loss: 1.6948e-02, Boundary loss: 4.5887e-02, Collocation loss : 1.1158e-03\n",
      "Iter 3500, Loss: 6.2830e-02, Initial loss: 1.7038e-02, Boundary loss: 4.4594e-02, Collocation loss : 1.1986e-03\n",
      "Iter 4000, Loss: 6.1649e-02, Initial loss: 1.6568e-02, Boundary loss: 4.3933e-02, Collocation loss : 1.1471e-03\n",
      "Iter 4500, Loss: 6.0892e-02, Initial loss: 1.6266e-02, Boundary loss: 4.3532e-02, Collocation loss : 1.0940e-03\n",
      "Iter 5000, Loss: 5.9900e-02, Initial loss: 1.5939e-02, Boundary loss: 4.2926e-02, Collocation loss : 1.0353e-03\n",
      "Iter 5500, Loss: 5.8501e-02, Initial loss: 1.5211e-02, Boundary loss: 4.2371e-02, Collocation loss : 9.1925e-04\n",
      "Iter 6000, Loss: 5.7730e-02, Initial loss: 1.5277e-02, Boundary loss: 4.1563e-02, Collocation loss : 8.9087e-04\n",
      "Iter 6500, Loss: 5.6726e-02, Initial loss: 1.4612e-02, Boundary loss: 4.1273e-02, Collocation loss : 8.4108e-04\n",
      "Iter 7000, Loss: 5.6187e-02, Initial loss: 1.5183e-02, Boundary loss: 4.0064e-02, Collocation loss : 9.3976e-04\n",
      "Iter 7500, Loss: 5.5508e-02, Initial loss: 1.4681e-02, Boundary loss: 4.0011e-02, Collocation loss : 8.1616e-04\n",
      "Iter 8000, Loss: 5.4973e-02, Initial loss: 1.4286e-02, Boundary loss: 3.9875e-02, Collocation loss : 8.1151e-04\n",
      "Iter 8500, Loss: 5.4509e-02, Initial loss: 1.3739e-02, Boundary loss: 4.0071e-02, Collocation loss : 7.0006e-04\n"
     ]
    }
   ],
   "source": [
    "model.train(print_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be353a9a-c898-4ff0-9cc9-e8be8b4c1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e5e4f-1a6d-41a0-9b93-bd0f0dd71088",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star = np.random.uniform(0, L, (100, 1))\n",
    "t_star = np.random.uniform(0, T, (100, 1))\n",
    "u_star = np.cos((np.pi * c * t_star) / (2 * L)) * np.cos((np.pi * x_star) / (2 * L))\n",
    "x_star = torch.tensor(x_star, requires_grad=True, dtype=torch.float32, device=device)\n",
    "t_star = torch.tensor(t_star, requires_grad=True, dtype=torch.float32, device=device)\n",
    "u_pred = model.net_u(x_star, t_star).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9a1ab-ea7e-4dbd-bba9-266494b5117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.mean(np.square(u_star - u_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22b61f-a85a-4acf-86ca-5b20f86a2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904821c-5466-4598-a0d7-f9df33c5dd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
