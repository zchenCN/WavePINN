{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b03770e-6a5f-46fd-9ca6-15ff6db7cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7e9a3-d266-430b-8159-9a7f70178732",
   "metadata": {},
   "source": [
    "We solve the following 1d homogenenous wave equation:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "&u_{tt} - c^2u_{xx} = 0, 0 < x < L, t > 0 \\\\\n",
    "&u(0, t) = u(L, t) = 0\\\\\n",
    "&u(x, 0) = \\cos\\frac{\\pi x}{2L}, u_t(x, 0) = 0\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "The theoretical solution of it is:\n",
    "$$ u(x, t) = \\cos\\frac{\\pi ct}{2L}\\cos\\frac{\\pi x}{2L}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f88d6c-c935-4bc8-b9db-278191b54d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2\n",
    "L = 1\n",
    "T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fe6a87-3c2f-42cc-8382-41cf5d52b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    \"\"\"Fully connected neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.linears.append(nn.Linear(layer_sizes[i-1], layer_sizes[i]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for linear in self.linears[:-1]:\n",
    "            x = torch.tanh(linear(x))\n",
    "            # x = torch.sin(linear(x))\n",
    "        x = self.linears[-1](x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63270bf0-a00e-4fd8-b6de-caae55932a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    \"\"\"Physic informed neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, c, L, T, layer_sizes, Ni, Nb, Nc):\n",
    "        super(PINN, self).__init__()\n",
    "        self.L = L\n",
    "        self.c = c \n",
    "        self.T = T\n",
    "        \n",
    "        # Initial condition\n",
    "        xi = np.random.uniform(0, L, (Ni, 1))\n",
    "        self.xi = torch.tensor(xi, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.t0 = torch.zeros(Ni, 1, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        \n",
    "        # Boundary condition\n",
    "        ta = np.random.uniform(0, T, (Nb, 1))\n",
    "        xa = np.ones((Nb, 1)) * 0\n",
    "        self.ta = torch.tensor(ta, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.xa = torch.tensor(xa, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        tb = np.random.uniform(0, T, (Nb, 1))\n",
    "        xb = np.ones((Nb, 1)) * L\n",
    "        self.tb = torch.tensor(tb, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.xb = torch.tensor(xb, dtype=torch.float32, requires_grad=True, device=device)        \n",
    "        \n",
    "        # Collocation points\n",
    "        xf = np.random.uniform(0, L, (Nc, 1))\n",
    "        tf = np.random.uniform(0, T, (Nc, 1))\n",
    "        self.xf = torch.tensor(xf, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.tf = torch.tensor(tf, dtype=torch.float32, requires_grad=True, device=device)\n",
    "                     \n",
    "        self.dnn = DNN(layer_sizes).to(device)\n",
    "        self.num_iter = 0\n",
    "        self.max_num_iter = 50000\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.dnn.parameters(),\n",
    "            lr = 0.0001,\n",
    "        )\n",
    "        \n",
    "    def net_u(self, x, t):\n",
    "        u = self.dnn(torch.cat((x, t), dim=1))\n",
    "        return u \n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_tt = torch.autograd.grad(\n",
    "            u_t, t, \n",
    "            grad_outputs=torch.ones_like(u_t),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        Lu = u_tt  - self.c**2 * u_xx\n",
    "        return Lu \n",
    "    \n",
    "    def initial_loss(self):\n",
    "        u = self.net_u(self.xi, self.t0)\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, self.t0, \n",
    "            grad_outputs=torch.ones_like(u), \n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        li = torch.mean(torch.square(u - torch.cos(np.pi * self.xi / (2 * L)))) + torch.mean(torch.square(u_t))\n",
    "        self.loss_i.append(li.item())\n",
    "        return li\n",
    "    \n",
    "    def boundary_loss(self):\n",
    "        ua = self.net_u(self.xa, self.ta)\n",
    "        ub = self.net_u(self.xb, self.tb)\n",
    "        lb = torch.mean(torch.square(ua)) +\\\n",
    "             torch.mean(torch.square(ub))\n",
    "        self.loss_b.append(lb.item())\n",
    "        return lb\n",
    "                        \n",
    "    def collocation_loss(self):\n",
    "        Lu = self.net_f(self.xf, self.tf)\n",
    "        lc = torch.mean(torch.square(Lu))\n",
    "        self.loss_c.append(lc.item())\n",
    "        return lc\n",
    "    \n",
    "    def compute_loss(self, l1, l2, l3, print_interval):\n",
    "        li = self.initial_loss()\n",
    "        lb = self.boundary_loss()\n",
    "        lc = self.collocation_loss()\n",
    "        l = l1 * li + l2 * lb + l3 * lc \n",
    "        # self.loss.append(l.item())\n",
    "        if self.num_iter % print_interval == 0 or self.num_iter == self.max_num_iter:\n",
    "            self.loss.append(l.item())\n",
    "            print(\"Iter %d, Loss: %.4e, Initial loss: %.4e, Boundary loss: %.4e, Collocation loss : %.4e\" \n",
    "                  % (self.num_iter, l.item(), li.item(), lb.item(), lc.item()))\n",
    "        return l\n",
    "\n",
    "    def train(self, l1=1, l2=1, l3=1, print_interval=100):\n",
    "        self.loss_i = []\n",
    "        self.loss_b = []\n",
    "        self.loss_c = []\n",
    "        self.loss = []\n",
    "        self.dnn.train()\n",
    "        while self.num_iter < self.max_num_iter:\n",
    "            l = self.compute_loss(l1, l2, l3, print_interval)\n",
    "            self.optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            self.optimizer.step()\n",
    "            self.num_iter += 1\n",
    "            \n",
    "    def predict(self, x, t):\n",
    "        self.dnn.eval() \n",
    "        x = torch.tensor(x, requires_grad=True, dtype=torch.float32, device=device)\n",
    "        t = torch.tensor(t, requires_grad=True, dtype=torch.float32, device=device)\n",
    "        u = self.net_u(x, t)\n",
    "        Lu = self.net_f(x, t)\n",
    "        u = u.detach().cpu().numpy()\n",
    "        Lu = Lu.detach().cpu().numpy()\n",
    "        return u, Lu\n",
    "    \n",
    "    # def plot_loss(self):\n",
    "    #     fig = plt.figure()\n",
    "    #     ax1 = fig.add_subplot(151)\n",
    "    #     ax1.plot(self.loss)\n",
    "    #     ax1.set_title('Loss')\n",
    "    #     ax2 = fig.add_subplot(152)\n",
    "    #     ax2.plot(self.loss_i)\n",
    "    #     ax2.set_title('Initial Loss')\n",
    "    #     ax3 = fig.add_subplot(153)\n",
    "    #     ax3.plot(self.loss_b)\n",
    "    #     ax3.set_title('Boundary Loss')\n",
    "    #     ax4 = fig.add_subplot(154)\n",
    "    #     ax4.plot(self.loss_c1)\n",
    "    #     ax4.set_title('Collocation Loss 1')\n",
    "    #     ax5 = fig.add_subplot(155)\n",
    "    #     ax5.plot(self.loss_c2)\n",
    "    #     ax5.set_title('Collocation Loss 2')\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb615e2-74b6-495b-851b-bb8f0018c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [2] + [64] * 8 + [1]\n",
    "Ni = 1000\n",
    "Nb = 1000\n",
    "Nc = 10000\n",
    "model = PINN(c, L, T, layer_sizes, Ni, Nb, Nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823635b9-7f81-4ce1-85df-ed5da7a2383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss: 5.0131e-01, Initial loss: 5.0124e-01, Boundary loss: 6.4513e-05, Collocation loss : 5.3422e-06\n",
      "Iter 500, Loss: 1.4037e-01, Initial loss: 5.2912e-02, Boundary loss: 8.1434e-02, Collocation loss : 6.0222e-03\n",
      "Iter 1000, Loss: 8.9788e-02, Initial loss: 2.5972e-02, Boundary loss: 6.1594e-02, Collocation loss : 2.2212e-03\n",
      "Iter 1500, Loss: 7.4575e-02, Initial loss: 2.1510e-02, Boundary loss: 5.0640e-02, Collocation loss : 2.4255e-03\n",
      "Iter 2000, Loss: 6.6159e-02, Initial loss: 1.8309e-02, Boundary loss: 4.5736e-02, Collocation loss : 2.1140e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_507/204832749.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_507/3681087200.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, l1, l2, l3, print_interval)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_507/3681087200.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, l1, l2, l3, print_interval)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundary_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollocation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mli\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# self.loss.append(l.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_507/3681087200.py\u001b[0m in \u001b[0;36mcollocation_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollocation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mLu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_507/3681087200.py\u001b[0m in \u001b[0;36mnet_f\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         u_t = torch.autograd.grad(\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/install/envs/cuda/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         inputs, allow_unused, accumulate_grad=False)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(print_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be353a9a-c898-4ff0-9cc9-e8be8b4c1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e5e4f-1a6d-41a0-9b93-bd0f0dd71088",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star = np.random.uniform(0, L, (100, 1))\n",
    "t_star = np.random.uniform(0, T, (100, 1))\n",
    "u_star = np.cos((np.pi * c * t_star) / (2 * L)) * np.cos((np.pi * x_star) / (2 * L))\n",
    "x_star = torch.tensor(x_star, requires_grad=True, dtype=torch.float32, device=device)\n",
    "t_star = torch.tensor(t_star, requires_grad=True, dtype=torch.float32, device=device)\n",
    "u_pred = model.net_u(x_star, t_star).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9a1ab-ea7e-4dbd-bba9-266494b5117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.mean(np.square(u_star - u_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22b61f-a85a-4acf-86ca-5b20f86a2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904821c-5466-4598-a0d7-f9df33c5dd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
