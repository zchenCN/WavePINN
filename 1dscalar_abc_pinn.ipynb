{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4783eef1-8657-47ee-b8a0-ac4fa6aee3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b79c6-c856-480f-9815-12a10aaf1388",
   "metadata": {},
   "source": [
    "The 1d scalar wave euqation with Mur ABC (Absorbing Boudary Condition) has the following form,:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "&u_{tt} - c^2(x)u_{xx} = f(x, t), a < x < b, t > 0 \\\\\n",
    "&u_t(a, t) - c(a)u_x(a, t) = 0\\\\\n",
    "&u_t(b, t) + c(b)u_x(b, t) = 0\\\\\n",
    "&u(x, 0) = 0\\\\\n",
    "&u_t(x, 0)  = 0 \n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "Specificlly, let $a = 0, b = 2, c=2, T = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26743712-10b0-4a31-9d46-04640359ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 2\n",
    "c = 2\n",
    "T = 1\n",
    "x0 = 1\n",
    "f0 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eddf160-4f75-444d-88ae-540ce02ea0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet(t, f0):\n",
    "    \"\"\"Ricker wavelet\n",
    "    \"\"\"\n",
    "    sigma = 1 / (np.pi * f0 * np.sqrt(2))\n",
    "    t0 = 6 * sigma\n",
    "    tmp = np.pi**2 * f0**2 * (t-t0)**2 \n",
    "    w = (1 - 2*tmp) * np.exp(-tmp)\n",
    "    return w\n",
    "\n",
    "def delta(x, x0, beta):\n",
    "    exp = np.exp(-(x-x0)**2 / beta)\n",
    "    return exp / np.sqrt(np.pi * beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d102e8d-029f-40f7-ba9e-dac811242ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    \"\"\"Fully connected neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.linears.append(nn.Linear(layer_sizes[i-1], layer_sizes[i]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for linear in self.linears[:-1]:\n",
    "            # x = torch.tanh(linear(x))\n",
    "            x = torch.sin(linear(x))\n",
    "        x = self.linears[-1](x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0c45da-a328-406c-afff-aa86ba1948e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    \"\"\"Physic informed neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, a, b, c, T, x0, f0, \n",
    "                 layer_sizes, alpha, beta, Ni, Nb, Nc1, Nc2):\n",
    "        super(PINN, self).__init__()\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c # constant first \n",
    "        self.T = T\n",
    "        self.x0 = x0\n",
    "        self.f0 = f0\n",
    "        \n",
    "        # Initial condition\n",
    "        x_i = np.random.uniform(a, b, (Ni, 1))\n",
    "        self.x_i = torch.tensor(x_i, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.t_0 = torch.zeros(Ni, 1, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        \n",
    "        # Boundary condition\n",
    "        t_a = np.random.uniform(0, T, (Nb, 1))\n",
    "        x_a = np.ones((Nb, 1)) * a\n",
    "        self.t_a = torch.tensor(t_a, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.x_a = torch.tensor(x_a, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        t_b = np.random.uniform(0, T, (Nb, 1))\n",
    "        x_b = np.ones((Nb, 1)) * b\n",
    "        self.t_b = torch.tensor(t_b, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.x_b = torch.tensor(x_b, dtype=torch.float32, requires_grad=True, device=device)        \n",
    "        \n",
    "        # Collocation points\n",
    "        assert a <= x0 - alpha <= x0 + alpha <= b \n",
    "        x_f1 = np.random.uniform(x0 - alpha, x0 + alpha, (Nc1, 1))\n",
    "        t_f1 = np.random.uniform(0, T, (Nc1, 1))\n",
    "        f1 = wavelet(t_f1, f0) * delta(x_f1, x0, beta)\n",
    "        self.x_f1 = torch.tensor(x_f1, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.t_f1 = torch.tensor(t_f1, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.f1 = torch.tensor(f1, dtype=torch.float32, device=device)\n",
    "        x_f2 = np.r_[np.random.uniform(0, x0 - alpha, (Nc2//2, 1)), \\\n",
    "                     np.random.uniform(x0 + alpha, b, (Nc2 - Nc2//2, 1))]\n",
    "        t_f2 = np.random.uniform(0, T, (Nc2, 1))\n",
    "        # f2 = wavelet(t_f2, f0) * delta(x_f2, x0, beta)\n",
    "        f2 = np.zeros((Nc2, 1))\n",
    "        self.x_f2 = torch.tensor(x_f2, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.t_f2 = torch.tensor(t_f2, dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.f2 = torch.tensor(f2, dtype=torch.float32, device=device)\n",
    "                     \n",
    "        self.dnn = DNN(layer_sizes).to(device)\n",
    "        self.num_iter = 0\n",
    "        self.max_num_iter = 10000\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.dnn.parameters(),\n",
    "            lr = 0.00001,\n",
    "        )\n",
    "        \n",
    "    def net_u(self, x, t):\n",
    "        u = self.dnn(torch.cat((x, t), dim=1))\n",
    "        return u \n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_tt = torch.autograd.grad(\n",
    "            u_t, t, \n",
    "            grad_outputs=torch.ones_like(u_t),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        Lu = u_tt  - self.c**2 * u_xx\n",
    "        return Lu \n",
    "    \n",
    "    def initial_loss(self):\n",
    "        u = self.net_u(self.x_i, self.t_0)\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, self.t_0, \n",
    "            grad_outputs=torch.ones_like(u), \n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        li = torch.mean(torch.square(u)) + torch.mean(torch.square(u_t))\n",
    "        self.loss_i.append(li.item())\n",
    "        return li\n",
    "    \n",
    "    def boundary_loss(self):\n",
    "        ua = self.net_u(self.x_a, self.t_a)\n",
    "        ub = self.net_u(self.x_b, self.t_b)\n",
    "        ua_t = torch.autograd.grad(\n",
    "            ua, self.t_a, \n",
    "            grad_outputs=torch.ones_like(ua), \n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        ua_x = torch.autograd.grad(\n",
    "            ua, self.x_a, \n",
    "            grad_outputs=torch.ones_like(ua), \n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        ub_t = torch.autograd.grad(\n",
    "            ub, self.t_b, \n",
    "            grad_outputs=torch.ones_like(ub), \n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        ub_x = torch.autograd.grad(\n",
    "            ub, self.x_b, \n",
    "            grad_outputs=torch.ones_like(ub), \n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        lb = torch.mean(torch.square(ua_t - self.c * ua_x)) +\\\n",
    "             torch.mean(torch.square(ub_t + self.c * ub_x))\n",
    "        self.loss_b.append(lb.item())\n",
    "        return lb\n",
    "                        \n",
    "    def collocation_loss1(self):\n",
    "        Lu1 = self.net_f(self.x_f1, self.t_f1)\n",
    "        lc1 = torch.mean(torch.square(Lu1 - self.f1))\n",
    "        self.loss_c1.append(lc1.item())\n",
    "        return lc1\n",
    "    \n",
    "    def collocation_loss2(self):\n",
    "        Lu2 = self.net_f(self.x_f2, self.t_f2)\n",
    "        lc2 = torch.mean(torch.square(Lu2 - self.f2))\n",
    "        self.loss_c2.append(lc2.item())\n",
    "        return lc2\n",
    "    \n",
    "    def compute_loss(self, l1, l2, l3, l4, print_interval):\n",
    "        li = self.initial_loss()\n",
    "        lb = self.boundary_loss()\n",
    "        lc1 = self.collocation_loss1()\n",
    "        lc2 = self.collocation_loss2()\n",
    "        l = l1 * li + l2 * lb + l3 * lc1 + l4 * lc2\n",
    "        self.loss.append(l.item())\n",
    "        if self.num_iter % print_interval == 0 or self.num_iter == self.max_num_iter:\n",
    "            print(\"Iter %d, Loss: %.4e, Initial loss: %.4e, Boundary loss: %.4e, Collocation loss 1: %.4e, Collocation loss 2: %.4e\" \n",
    "                  % (self.num_iter, l.item(), li.item(), lb.item(), lc1.item(), lc2.item()))\n",
    "        return l\n",
    "\n",
    "    def train(self, l1=1, l2=1, l3=1, l4=1, print_interval=100):\n",
    "        self.loss_i = []\n",
    "        self.loss_b = []\n",
    "        self.loss_c1 = []\n",
    "        self.loss_c2 = []\n",
    "        self.loss = []\n",
    "        self.dnn.train()\n",
    "        while self.num_iter < self.max_num_iter:\n",
    "            l = self.compute_loss(l1, l2, l3, l4, print_interval)\n",
    "            self.optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            self.optimizer.step()\n",
    "            self.num_iter += 1\n",
    "            \n",
    "    def predict(self):\n",
    "        self.dnn.eval() \n",
    "        x = np.arange(200) * 0.01\n",
    "        t = np.arange(300) * 0.003\n",
    "        X, T = np.meshgrid(x, t)\n",
    "        x_test = torch.tensor(X.flatten()[:, np.newaxis], requires_grad=True, dtype=torch.float32, device=device)\n",
    "        t_test = torch.tensor(T.flatten()[:, np.newaxis], requires_grad=True, dtype=torch.float32, device=device)\n",
    "        u_test = self.net_u(x_test, t_test)\n",
    "        Lu_test = self.net_f(x_test, t_test)\n",
    "        u_test = u_test.detach().cpu().numpy().reshape(200, 300)\n",
    "        Lu_test = Lu_test.detach().cpu().numpy().reshape(200, 300)\n",
    "        return u, Lu\n",
    "    \n",
    "    # def plot_loss(self):\n",
    "    #     fig = plt.figure()\n",
    "    #     ax1 = fig.add_subplot(151)\n",
    "    #     ax1.plot(self.loss)\n",
    "    #     ax1.set_title('Loss')\n",
    "    #     ax2 = fig.add_subplot(152)\n",
    "    #     ax2.plot(self.loss_i)\n",
    "    #     ax2.set_title('Initial Loss')\n",
    "    #     ax3 = fig.add_subplot(153)\n",
    "    #     ax3.plot(self.loss_b)\n",
    "    #     ax3.set_title('Boundary Loss')\n",
    "    #     ax4 = fig.add_subplot(154)\n",
    "    #     ax4.plot(self.loss_c1)\n",
    "    #     ax4.set_title('Collocation Loss 1')\n",
    "    #     ax5 = fig.add_subplot(155)\n",
    "    #     ax5.plot(self.loss_c2)\n",
    "    #     ax5.set_title('Collocation Loss 2')\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03a4c05-7698-4f19-bd3f-ff17af456632",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [2] + [64] * 8 + [1]\n",
    "beta = 0.01\n",
    "alpha = 3 * beta\n",
    "Ni = 1000\n",
    "Nb = 1000\n",
    "Nc1 = 1000\n",
    "Nc2 = 3000\n",
    "model = PINN(a, b, c, T, x0, f0, \\\n",
    "            layer_sizes, alpha, beta, Ni, Nb, Nc1, Nc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e03b1fc-4694-4e5f-841a-596e852ef830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss: 9.2772e-02, Initial loss: 3.0757e-03, Boundary loss: 4.2546e-05, Collocation loss 1: 8.9620e-01, Collocation loss 2: 3.4238e-05\n",
      "Iter 500, Loss: 8.9922e-02, Initial loss: 3.4695e-05, Boundary loss: 2.1526e-04, Collocation loss 1: 8.9615e-01, Collocation loss 2: 5.7578e-05\n",
      "Iter 1000, Loss: 8.9983e-02, Initial loss: 3.2314e-04, Boundary loss: 4.4370e-05, Collocation loss 1: 8.9609e-01, Collocation loss 2: 6.2475e-06\n",
      "Iter 1500, Loss: 8.9714e-02, Initial loss: 8.2582e-05, Boundary loss: 1.9706e-05, Collocation loss 1: 8.9601e-01, Collocation loss 2: 1.0735e-05\n",
      "Iter 2000, Loss: 9.0060e-02, Initial loss: 4.3517e-04, Boundary loss: 8.2234e-06, Collocation loss 1: 8.9609e-01, Collocation loss 2: 7.3471e-06\n",
      "Iter 2500, Loss: 9.0005e-02, Initial loss: 3.3334e-04, Boundary loss: 6.2324e-05, Collocation loss 1: 8.9607e-01, Collocation loss 2: 2.4966e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_432/2602240510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_432/2222104909.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, l1, l2, l3, l4, print_interval)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/install/envs/cuda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/install/envs/cuda/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(l1=1, l2=1, l3=0.1, l4=1, print_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f583cb-6273-47d7-b55b-1b219be64d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c801874-04fa-441a-973b-fb2dc23def39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef4fae-bdd5-48f0-9596-6389d5843162",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3fb37-5192-4781-b551-553b4513d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e2949-c6bc-4e3c-bc7b-dbbd86e5459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9fef3-82c7-45f6-bcfb-684369fed7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u, Lu = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07eb588-b5b4-470b-b0ab-0db04b0dfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.f2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d613230-9642-4bc0-86c8-d29380bf6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test initial parameters xavier\n",
    "# fist deal with lc1 then adding l1 lb and lc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8289f5c-7891-4557-bd70-af84a40cb8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
